# Header -----------------------------------------------------------------------
#
# Script name: quanteda-defaults.R
#
# Purpose of script: This runs quanteda functions with my own defaults for the
# populism dictionary.
#
# Author: Johann Gr√ºndl
# Email: mail@johanngruendl.at
#
# Date created: 2019-11-11
#
# ******************************************************************************

#' Creates quanteda tokens with default settings
#'
#' @description This function creates quanteda tokens according to my
#' pre-defined settings. This function is basically a wrapper for
#' quanteda's tokens function. Using this function makes sure that the same
#' settings are applied all the time. When create_compounds = TRUE you can also
#' provide a dictionary and create multi-word compounds for complex regular (or
#' glob) expressions using the make_compounds function from the multidictR
#' package.
#'
#' @param text A quanteda corpus object or something that can be transformed to
#' a tokens object by quanteda::tokens().
#' @param create_compounds Should compounds for provided multi-word patterns be
#' created before tokenizing? Defaults to FALSE.
#' @param compounds_at_level If compounds for patterns are created, at which
#' level should patterns be applied? Possible values are "documents",
#' "sentences", or "paragraphs". Defaults to "sentences".
#' @param compounds_dict If compounds for patterns are created, which patterns
#' should be applied? Needs to be set if create_compounds = TRUE. You can
#' provide a quanteda dictionary object or a character vector where each element
#' is a pattern. Patterns are expected to be regular expressions (if
#' compounds_dict_glob parameter is not set to TRUE) or only include glob-style
#' wildcards (if compound_dict_glob parameter is set to TRUE).
#' @param compounds_dict_glob If compounds for patterns are created, do the
#' provided patterns use glob-style wildcards instead of regular expressions?
#' Defaults to FALSE.
#'
#' @return A quanteda tokens object.
#'
#' @export
get_pop_tokens <- function(
  text,
  create_compounds = FALSE,
  compounds_at_level = "sentences",
  compounds_dict = NULL,
  compounds_dict_glob = FALSE
) {

  if (create_compounds & is.null(compounds_dict)) {
    warning(paste0("You tried to create compounds for this corpus, but no ",
                   "dictionary for compound creation has been provided."))
  }

  # Create compounds if param is set
  if (create_compounds & !is.null(compounds_dict)) {
    # Compounds are created
    text <- multidictR::make_compounds(
      text = text,
      patterns = compounds_dict,
      at_level = compounds_at_level,
      glob = compounds_dict_glob,
      lazy = TRUE,
      ignore_case = TRUE,
      optimize_regex = TRUE)
  }

  ### Here the default settings for the tokenizer are made ###
  toks <- quanteda::tokens(
    text,
    what = "word",
    remove_punct = TRUE,
    remove_symbols = TRUE,
    remove_numbers = TRUE,
    remove_url = TRUE,
    remove_separators = TRUE,
    split_hyphens = FALSE,
    include_docvars = TRUE
  )
  toks <- quanteda::tokens_tolower(toks, keep_acronyms = FALSE)
  return(toks)
}

#' Transform tokens to a quanteda dfm object
#'
#' @description This function transforms a tokens object to a quanteda dfm
#' object. It makes some settings which ensure that dfm creation always uses
#' the same parameters. However, most of the settings are already made during
#' token creation in the function get_pop_tokens. This function is mainly for
#' transforming such a tokens object to a dfm object. It is basically a wrapper
#' for quanteda::dfm().
#'
#' @param tokens A quanteda tokens object, usually generated by the
#' get_pop_tokens provided with this package.
#' @param stopwords Stopwords are words or tokens which are removed from the
#' dfm. Defaults to NULL.
#'
#' @return A quanteda dfm object.
#'
#' @export
pop_tokens_to_dfm <- function(tokens, stopwords = NULL) {
  ### Here settings for dfm creation could be changed ###
  return(
    quanteda::dfm(
      x = tokens,
      tolower = TRUE, # actually already done in get_pop_tokens
      stem = FALSE,
      select = NULL,
      remove = stopwords,
      dictionary = NULL,
      case_insensitive = TRUE,
      groups = NULL
    )
  )
}

#' Create a quanteda dfm object
#'
#' @description This function provides a unified way for creating quanteda dfm
#' objects with identical settings. This function is basically a replacement for
#' quanteda's dfm function. It calls get_pop_tokens and pop_tokens_to_dfm from
#' this package. Using this function makes sure that the same settings are
#' applied all the time. When create_compounds = TRUE you can also provide a
#' dictionary and create multi-word compounds for complex regular (or glob)
#' expressions using the make_compounds function from the multidictR package.
#'
#' @param text A quanteda corpus object or something that can be transformed to
#' a tokens object by quanteda::tokens().
#' @param stopwords Stopwords are words or tokens which are removed from the
#' dfm. Defaults to NULL.
#' @param create_compounds Should compounds for provided multi-word patterns be
#' created before tokenizing? Defaults to FALSE.
#' @param compounds_at_level If compounds for patterns are created, at which
#' level should patterns be applied? Possible values are "documents",
#' "sentences", or "paragraphs". Defaults to "sentences".
#' @param compounds_dict If compounds for patterns are created, which patterns
#' should be applied? Needs to be set if create_compounds = TRUE. You can
#' provide a quanteda dictionary object or a character vector where each element
#' is a pattern. Patterns are expected to be regular expressions (if
#' compounds_dict_glob parameter is not set to TRUE) or only include glob-style
#' wildcards (if compound_dict_glob parameter is set to TRUE).
#' @param compounds_dict_glob If compounds for patterns are created, do the
#' provided patterns use glob-style wildcards instead of regular expressions?
#' Defaults to FALSE.
#'
#' @return A quanteda dfm object.
#'
#' @export
get_pop_dfm <- function(
  text,
  stopwords = NULL,
  create_compounds = FALSE,
  compounds_at_level = "sentences",
  compounds_dict = NULL,
  compounds_dict_glob = FALSE
) {
  toks <- get_pop_tokens(
    text = text,
    create_compounds = create_compounds,
    compounds_at_level = compounds_at_level,
    compounds_dict = compounds_dict,
    compounds_dict_glob = compounds_dict_glob
  )
  return(
    pop_tokens_to_dfm(
      tokens = toks,
      stopwords = stopwords
    )
  )
}
